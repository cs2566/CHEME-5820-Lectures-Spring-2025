{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edea839-d6ec-4e40-802a-4abd1e2ae4ab",
   "metadata": {},
   "source": [
    "# L3a: Linear regression models for prediction and classification tasks\n",
    "This lecture explores linear regression models for prediction and classification. Linear regression predicts continuous target variables using one or more features (prediction) and classifies objects based on features (classification). These models are easy to implement and interpret, serving as a foundation for more complex predictive analytics algorithms.\n",
    "\n",
    "There are several key ideas in this lecture:\n",
    "\n",
    "* __Linear regression__ is a statistical method for modeling the relationship between a dependent variable (target) and one or more independent variables (features) by fitting a linear equation to observed data. It provides a simple way to predict outcomes and understand relationships between variables.\n",
    "* __Continuous variable__ prediction tasks: In machine learning, linear regression models are commonly employed for continuous variable prediction tasks. These models enable the estimation of numerical outcomes based on the (non)linear relationships identified between input features and the target variable.\n",
    "* __Classification tasks__: While linear regression is primarily designed to predict continuous outcomes, it can also be adapted for classification tasks by combining the linear regression model with an output function that transforms the continuous target variable predictions into discrete classes or probability estimates. In this lecture, we'll consider binary classification using [the perceptron classification algorithm, developed at Cornell in the 1950s](https://en.wikipedia.org/wiki/Perceptron)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f92d34-8caa-42d5-a09a-2a0cec96285a",
   "metadata": {},
   "source": [
    "### Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6f0689-34c4-4758-8427-e7de25160311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Project.toml`\n",
      "  \u001b[90m[336ed68f] \u001b[39m\u001b[92m+ CSV v0.10.15\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.7.0\u001b[39m\n",
      "  \u001b[90m[31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.117\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.16.6\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.9\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.4\u001b[39m\n",
      "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.7\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[93m~ LinearAlgebra ⇒ v1.11.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Manifest.toml`\n",
      "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.1.1\u001b[39m\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[92m+ AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.5.4\u001b[39m\n",
      "  \u001b[90m[13072b0f] \u001b[39m\u001b[92m+ AxisAlgorithms v1.1.0\u001b[39m\n",
      "  \u001b[90m[d1d4a3ce] \u001b[39m\u001b[92m+ BitFlags v0.1.9\u001b[39m\n",
      "  \u001b[90m[336ed68f] \u001b[39m\u001b[92m+ CSV v0.10.15\u001b[39m\n",
      "  \u001b[90m[d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.25.1\u001b[39m\n",
      "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
      "  \u001b[90m[944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.6\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.28.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.0\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.0\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.16.0\u001b[39m\n",
      "  \u001b[90m[f0e56b4a] \u001b[39m\u001b[92m+ ConcurrentUtilities v2.4.3\u001b[39m\n",
      "  \u001b[90m[d38c429a] \u001b[39m\u001b[92m+ Contour v0.6.3\u001b[39m\n",
      "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.7.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.20\u001b[39m\n",
      "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
      "  \u001b[90m[8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles v1.9.1\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[31c24e10] \u001b[39m\u001b[92m+ Distributions v0.25.117\u001b[39m\n",
      "  \u001b[90m[ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.3\u001b[39m\n",
      "  \u001b[90m[460bff9d] \u001b[39m\u001b[92m+ ExceptionUnwrapping v0.1.11\u001b[39m\n",
      "  \u001b[90m[c87230d0] \u001b[39m\u001b[92m+ FFMPEG v0.4.2\u001b[39m\n",
      "  \u001b[90m[7a1cc6ca] \u001b[39m\u001b[92m+ FFTW v1.8.1\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.16.6\u001b[39m\n",
      "  \u001b[90m[48062228] \u001b[39m\u001b[92m+ FilePathsBase v0.9.22\u001b[39m\n",
      "  \u001b[90m[1a297f60] \u001b[39m\u001b[92m+ FillArrays v1.13.0\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[1fa38f19] \u001b[39m\u001b[92m+ Format v1.3.7\u001b[39m\n",
      "  \u001b[90m[28b8d3ca] \u001b[39m\u001b[92m+ GR v0.73.12\u001b[39m\n",
      "  \u001b[90m[42e2da0e] \u001b[39m\u001b[92m+ Grisu v1.0.2\u001b[39m\n",
      "  \u001b[90m[cd3eb016] \u001b[39m\u001b[92m+ HTTP v1.10.15\u001b[39m\n",
      "  \u001b[90m[34004b35] \u001b[39m\u001b[92m+ HypergeometricFunctions v0.3.27\u001b[39m\n",
      "  \u001b[90m[842dd82b] \u001b[39m\u001b[92m+ InlineStrings v1.4.2\u001b[39m\n",
      "  \u001b[90m[a98d9a8b] \u001b[39m\u001b[92m+ Interpolations v0.15.1\u001b[39m\n",
      "  \u001b[90m[41ab1584] \u001b[39m\u001b[92m+ InvertedIndices v1.3.1\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.4\u001b[39m\n",
      "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
      "  \u001b[90m[1019f520] \u001b[39m\u001b[92m+ JLFzf v0.1.9\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.0\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      "  \u001b[90m[5ab0869b] \u001b[39m\u001b[92m+ KernelDensity v0.6.9\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[23fbe1c1] \u001b[39m\u001b[92m+ Latexify v0.16.5\u001b[39m\n",
      "  \u001b[90m[2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.29\u001b[39m\n",
      "  \u001b[90m[e6f89c97] \u001b[39m\u001b[92m+ LoggingExtras v1.1.0\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.15\u001b[39m\n",
      "  \u001b[90m[739be429] \u001b[39m\u001b[92m+ MbedTLS v1.1.9\u001b[39m\n",
      "  \u001b[90m[442fdcdd] \u001b[39m\u001b[92m+ Measures v0.3.2\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[6f286f6a] \u001b[39m\u001b[92m+ MultivariateStats v0.10.3\u001b[39m\n",
      "  \u001b[90m[77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.1.2\u001b[39m\n",
      "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.21\u001b[39m\n",
      "  \u001b[90m[510215fc] \u001b[39m\u001b[92m+ Observables v0.5.5\u001b[39m\n",
      "  \u001b[90m[6fe1bfb0] \u001b[39m\u001b[92m+ OffsetArrays v1.15.0\u001b[39m\n",
      "  \u001b[90m[4d8831e6] \u001b[39m\u001b[92m+ OpenSSL v1.4.3\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.0\u001b[39m\n",
      "  \u001b[90m[90014a1f] \u001b[39m\u001b[92m+ PDMats v0.11.32\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.1\u001b[39m\n",
      "  \u001b[90m[b98c9c47] \u001b[39m\u001b[92m+ Pipe v1.3.0\u001b[39m\n",
      "  \u001b[90m[ccf2f8ad] \u001b[39m\u001b[92m+ PlotThemes v3.3.0\u001b[39m\n",
      "  \u001b[90m[995b91a9] \u001b[39m\u001b[92m+ PlotUtils v1.4.3\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.9\u001b[39m\n",
      "  \u001b[90m[2dfb63ee] \u001b[39m\u001b[92m+ PooledArrays v1.4.3\u001b[39m\n",
      "  \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.3\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[92m+ PtrArrays v1.3.0\u001b[39m\n",
      "  \u001b[90m[1fd47b50] \u001b[39m\u001b[92m+ QuadGK v2.11.1\u001b[39m\n",
      "  \u001b[90m[c84ed2f1] \u001b[39m\u001b[92m+ Ratios v0.4.5\u001b[39m\n",
      "  \u001b[90m[3cdcf5f2] \u001b[39m\u001b[92m+ RecipesBase v1.3.4\u001b[39m\n",
      "  \u001b[90m[01d81517] \u001b[39m\u001b[92m+ RecipesPipeline v0.6.12\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[05181044] \u001b[39m\u001b[92m+ RelocatableFolders v1.0.1\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.0\u001b[39m\n",
      "  \u001b[90m[79098fc4] \u001b[39m\u001b[92m+ Rmath v0.8.0\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.2.1\u001b[39m\n",
      "  \u001b[90m[91c51154] \u001b[39m\u001b[92m+ SentinelArrays v1.4.8\u001b[39m\n",
      "  \u001b[90m[992d4aef] \u001b[39m\u001b[92m+ Showoff v1.0.3\u001b[39m\n",
      "  \u001b[90m[777ac1f9] \u001b[39m\u001b[92m+ SimpleBufferStream v1.2.0\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.1\u001b[39m\n",
      "  \u001b[90m[276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.5.0\u001b[39m\n",
      "  \u001b[90m[860ef19b] \u001b[39m\u001b[92m+ StableRNGs v1.0.2\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.11\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.3\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.7.0\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.4\u001b[39m\n",
      "  \u001b[90m[4c63d2b9] \u001b[39m\u001b[92m+ StatsFuns v1.3.2\u001b[39m\n",
      "  \u001b[90m[f3b207a7] \u001b[39m\u001b[92m+ StatsPlots v0.15.7\u001b[39m\n",
      "  \u001b[90m[892a3eda] \u001b[39m\u001b[92m+ StringManipulation v0.4.0\u001b[39m\n",
      "  \u001b[90m[ab02a1b2] \u001b[39m\u001b[92m+ TableOperations v1.2.0\u001b[39m\n",
      "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
      "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.0\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.11.3\u001b[39m\n",
      "  \u001b[90m[5c2747f8] \u001b[39m\u001b[92m+ URIs v1.5.1\u001b[39m\n",
      "  \u001b[90m[1cfade01] \u001b[39m\u001b[92m+ UnicodeFun v0.4.1\u001b[39m\n",
      "  \u001b[90m[1986cc42] \u001b[39m\u001b[92m+ Unitful v1.22.0\u001b[39m\n",
      "  \u001b[90m[45397f5d] \u001b[39m\u001b[92m+ UnitfulLatexify v1.6.4\u001b[39m\n",
      "  \u001b[90m[41fe7b60] \u001b[39m\u001b[92m+ Unzip v0.2.0\u001b[39m\n",
      "  \u001b[90m[ea10d353] \u001b[39m\u001b[92m+ WeakRefStrings v1.4.2\u001b[39m\n",
      "  \u001b[90m[cc8bc4a8] \u001b[39m\u001b[92m+ Widgets v0.6.7\u001b[39m\n",
      "  \u001b[90m[efce3f68] \u001b[39m\u001b[92m+ WoodburyMatrices v1.0.0\u001b[39m\n",
      "  \u001b[90m[76eceee3] \u001b[39m\u001b[92m+ WorkerUtilities v1.6.1\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[68821587] \u001b[39m\u001b[92m+ Arpack_jll v3.5.1+1\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "  \u001b[90m[83423d85] \u001b[39m\u001b[92m+ Cairo_jll v1.18.2+1\u001b[39m\n",
      "  \u001b[90m[ee1fde0b] \u001b[39m\u001b[92m+ Dbus_jll v1.14.10+0\u001b[39m\n",
      "  \u001b[90m[2702e6a9] \u001b[39m\u001b[92m+ EpollShim_jll v0.0.20230411+1\u001b[39m\n",
      "  \u001b[90m[2e619515] \u001b[39m\u001b[92m+ Expat_jll v2.6.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[b22a6f82] \u001b[39m\u001b[92m+ FFMPEG_jll v4.4.4+1\u001b[39m\n",
      "  \u001b[90m[f5851436] \u001b[39m\u001b[92m+ FFTW_jll v3.3.10+3\u001b[39m\n",
      "  \u001b[90m[a3f928ae] \u001b[39m\u001b[92m+ Fontconfig_jll v2.15.0+0\u001b[39m\n",
      "  \u001b[90m[d7e528f0] \u001b[39m\u001b[92m+ FreeType2_jll v2.13.3+1\u001b[39m\n",
      "  \u001b[90m[559328eb] \u001b[39m\u001b[92m+ FriBidi_jll v1.0.16+0\u001b[39m\n",
      "  \u001b[90m[0656b61e] \u001b[39m\u001b[92m+ GLFW_jll v3.4.0+2\u001b[39m\n",
      "  \u001b[90m[d2c73de3] \u001b[39m\u001b[92m+ GR_jll v0.73.12+0\u001b[39m\n",
      "  \u001b[90m[78b55507] \u001b[39m\u001b[92m+ Gettext_jll v0.21.0+0\u001b[39m\n",
      "  \u001b[90m[7746bdde] \u001b[39m\u001b[92m+ Glib_jll v2.82.4+0\u001b[39m\n",
      "  \u001b[90m[3b182d85] \u001b[39m\u001b[92m+ Graphite2_jll v1.3.14+1\u001b[39m\n",
      "  \u001b[90m[2e76f6c2] \u001b[39m\u001b[92m+ HarfBuzz_jll v8.5.0+0\u001b[39m\n",
      "  \u001b[90m[1d5cc7b8] \u001b[39m\u001b[92m+ IntelOpenMP_jll v2025.0.4+0\u001b[39m\n",
      "  \u001b[90m[aacddb02] \u001b[39m\u001b[92m+ JpegTurbo_jll v3.1.1+0\u001b[39m\n",
      "  \u001b[90m[c1c5ebd0] \u001b[39m\u001b[92m+ LAME_jll v3.100.2+0\u001b[39m\n",
      "  \u001b[90m[88015f11] \u001b[39m\u001b[92m+ LERC_jll v4.0.1+0\u001b[39m\n",
      "  \u001b[90m[1d63c593] \u001b[39m\u001b[92m+ LLVMOpenMP_jll v18.1.7+0\u001b[39m\n",
      "  \u001b[90m[dd4b983a] \u001b[39m\u001b[92m+ LZO_jll v2.10.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[e9f186c6] \u001b[39m\u001b[92m+ Libffi_jll v3.2.2+2\u001b[39m\n",
      "  \u001b[90m[d4300ac3] \u001b[39m\u001b[92m+ Libgcrypt_jll v1.11.0+0\u001b[39m\n",
      "  \u001b[90m[7e76a0d4] \u001b[39m\u001b[92m+ Libglvnd_jll v1.7.0+0\u001b[39m\n",
      "  \u001b[90m[7add5ba3] \u001b[39m\u001b[92m+ Libgpg_error_jll v1.51.1+0\u001b[39m\n",
      "  \u001b[90m[94ce4f54] \u001b[39m\u001b[92m+ Libiconv_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[4b2f31a3] \u001b[39m\u001b[92m+ Libmount_jll v2.40.3+0\u001b[39m\n",
      "  \u001b[90m[89763e89] \u001b[39m\u001b[92m+ Libtiff_jll v4.7.1+0\u001b[39m\n",
      "  \u001b[90m[38a345b3] \u001b[39m\u001b[92m+ Libuuid_jll v2.40.3+0\u001b[39m\n",
      "  \u001b[90m[856f044c] \u001b[39m\u001b[92m+ MKL_jll v2025.0.1+1\u001b[39m\n",
      "  \u001b[90m[e7412a2a] \u001b[39m\u001b[92m+ Ogg_jll v1.3.5+1\u001b[39m\n",
      "  \u001b[90m[458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v3.0.15+3\u001b[39m\n",
      "  \u001b[90m[efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.6+0\u001b[39m\n",
      "  \u001b[90m[91d4177d] \u001b[39m\u001b[92m+ Opus_jll v1.3.3+0\u001b[39m\n",
      "  \u001b[90m[36c8627f] \u001b[39m\u001b[92m+ Pango_jll v1.55.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[30392449] \u001b[39m\u001b[92m+ Pixman_jll v0.43.4+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[c0090381] \u001b[39m\u001b[92m+ Qt6Base_jll v6.7.1+1\u001b[39m\n",
      "  \u001b[90m[629bc702] \u001b[39m\u001b[92m+ Qt6Declarative_jll v6.7.1+2\u001b[39m\n",
      "  \u001b[90m[ce943373] \u001b[39m\u001b[92m+ Qt6ShaderTools_jll v6.7.1+1\u001b[39m\n",
      "  \u001b[90m[e99dba38] \u001b[39m\u001b[92m+ Qt6Wayland_jll v6.7.1+1\u001b[39m\n",
      "  \u001b[90m[f50d1b31] \u001b[39m\u001b[92m+ Rmath_jll v0.5.1+0\u001b[39m\n",
      "  \u001b[90m[a44049a8] \u001b[39m\u001b[92m+ Vulkan_Loader_jll v1.3.243+0\u001b[39m\n",
      "  \u001b[90m[a2964d1f] \u001b[39m\u001b[92m+ Wayland_jll v1.21.0+2\u001b[39m\n",
      "  \u001b[90m[2381bf8a] \u001b[39m\u001b[92m+ Wayland_protocols_jll v1.36.0+0\u001b[39m\n",
      "  \u001b[90m[02c8fc9c] \u001b[39m\u001b[92m+ XML2_jll v2.13.5+0\u001b[39m\n",
      "  \u001b[90m[aed1982a] \u001b[39m\u001b[92m+ XSLT_jll v1.1.42+0\u001b[39m\n",
      "  \u001b[90m[ffd25f8a] \u001b[39m\u001b[92m+ XZ_jll v5.6.4+1\u001b[39m\n",
      "  \u001b[90m[f67eecfb] \u001b[39m\u001b[92m+ Xorg_libICE_jll v1.1.1+0\u001b[39m\n",
      "  \u001b[90m[c834827a] \u001b[39m\u001b[92m+ Xorg_libSM_jll v1.2.4+0\u001b[39m\n",
      "  \u001b[90m[4f6342f7] \u001b[39m\u001b[92m+ Xorg_libX11_jll v1.8.6+3\u001b[39m\n",
      "  \u001b[90m[0c0b7dd1] \u001b[39m\u001b[92m+ Xorg_libXau_jll v1.0.12+0\u001b[39m\n",
      "  \u001b[90m[935fb764] \u001b[39m\u001b[92m+ Xorg_libXcursor_jll v1.2.3+0\u001b[39m\n",
      "  \u001b[90m[a3789734] \u001b[39m\u001b[92m+ Xorg_libXdmcp_jll v1.1.5+0\u001b[39m\n",
      "  \u001b[90m[1082639a] \u001b[39m\u001b[92m+ Xorg_libXext_jll v1.3.6+3\u001b[39m\n",
      "  \u001b[90m[d091e8ba] \u001b[39m\u001b[92m+ Xorg_libXfixes_jll v6.0.0+0\u001b[39m\n",
      "  \u001b[90m[a51aa0fd] \u001b[39m\u001b[92m+ Xorg_libXi_jll v1.8.2+0\u001b[39m\n",
      "  \u001b[90m[d1454406] \u001b[39m\u001b[92m+ Xorg_libXinerama_jll v1.1.5+0\u001b[39m\n",
      "  \u001b[90m[ec84b674] \u001b[39m\u001b[92m+ Xorg_libXrandr_jll v1.5.4+0\u001b[39m\n",
      "  \u001b[90m[ea2f1a96] \u001b[39m\u001b[92m+ Xorg_libXrender_jll v0.9.11+1\u001b[39m\n",
      "  \u001b[90m[14d82f49] \u001b[39m\u001b[92m+ Xorg_libpthread_stubs_jll v0.1.2+0\u001b[39m\n",
      "  \u001b[90m[c7cfdc94] \u001b[39m\u001b[92m+ Xorg_libxcb_jll v1.17.0+3\u001b[39m\n",
      "  \u001b[90m[cc61e674] \u001b[39m\u001b[92m+ Xorg_libxkbfile_jll v1.1.2+1\u001b[39m\n",
      "  \u001b[90m[e920d4aa] \u001b[39m\u001b[92m+ Xorg_xcb_util_cursor_jll v0.1.4+0\u001b[39m\n",
      "  \u001b[90m[12413925] \u001b[39m\u001b[92m+ Xorg_xcb_util_image_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[2def613f] \u001b[39m\u001b[92m+ Xorg_xcb_util_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[975044d2] \u001b[39m\u001b[92m+ Xorg_xcb_util_keysyms_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[0d47668e] \u001b[39m\u001b[92m+ Xorg_xcb_util_renderutil_jll v0.3.9+1\u001b[39m\n",
      "  \u001b[90m[c22f9ab0] \u001b[39m\u001b[92m+ Xorg_xcb_util_wm_jll v0.4.1+1\u001b[39m\n",
      "  \u001b[90m[35661453] \u001b[39m\u001b[92m+ Xorg_xkbcomp_jll v1.4.6+1\u001b[39m\n",
      "  \u001b[90m[33bec58e] \u001b[39m\u001b[92m+ Xorg_xkeyboard_config_jll v2.39.0+0\u001b[39m\n",
      "  \u001b[90m[c5fb5394] \u001b[39m\u001b[92m+ Xorg_xtrans_jll v1.5.1+0\u001b[39m\n",
      "  \u001b[90m[3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.5.7+0\u001b[39m\n",
      "  \u001b[90m[35ca27e7] \u001b[39m\u001b[92m+ eudev_jll v3.2.9+0\u001b[39m\n",
      "  \u001b[90m[214eeab7] \u001b[39m\u001b[92m+ fzf_jll v0.56.3+0\u001b[39m\n",
      "  \u001b[90m[1a1c6b14] \u001b[39m\u001b[92m+ gperf_jll v3.1.1+1\u001b[39m\n",
      "  \u001b[90m[a4ae2306] \u001b[39m\u001b[92m+ libaom_jll v3.11.0+0\u001b[39m\n",
      "  \u001b[90m[0ac62f75] \u001b[39m\u001b[92m+ libass_jll v0.15.2+0\u001b[39m\n",
      "  \u001b[90m[1183f4f0] \u001b[39m\u001b[92m+ libdecor_jll v0.2.2+0\u001b[39m\n",
      "  \u001b[90m[2db6ffa8] \u001b[39m\u001b[92m+ libevdev_jll v1.11.0+0\u001b[39m\n",
      "  \u001b[90m[f638f0a6] \u001b[39m\u001b[92m+ libfdk_aac_jll v2.0.3+0\u001b[39m\n",
      "  \u001b[90m[36db933b] \u001b[39m\u001b[92m+ libinput_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[b53b4c65] \u001b[39m\u001b[92m+ libpng_jll v1.6.46+0\u001b[39m\n",
      "  \u001b[90m[f27f6e37] \u001b[39m\u001b[92m+ libvorbis_jll v1.3.7+2\u001b[39m\n",
      "  \u001b[90m[009596ad] \u001b[39m\u001b[92m+ mtdev_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[1317d2d5] \u001b[39m\u001b[92m+ oneTBB_jll v2021.12.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1270edf5] \u001b[39m\u001b[92m+ x264_jll v2021.5.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[dfaa095f] \u001b[39m\u001b[92m+ x265_jll v3.5.0+0\u001b[39m\n",
      "  \u001b[90m[d8fb68d0] \u001b[39m\u001b[92m+ xkbcommon_jll v1.4.1+2\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[8ba89e20] \u001b[39m\u001b[92m+ Distributed v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.11.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.11.0\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[1a1011a3] \u001b[39m\u001b[92m+ SharedArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[f489334b] \u001b[39m\u001b[92m+ StyledStrings v1.11.0\u001b[39m\n",
      "  \u001b[90m[4607b0f0] \u001b[39m\u001b[92m+ SuiteSparse\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[92m+ Test v1.11.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.1.1+0\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.6.0+0\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.7.2+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.6+0\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2023.12.12\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.27+1\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.1+2\u001b[39m\n",
      "  \u001b[90m[efcefdf7] \u001b[39m\u001b[92m+ PCRE2_jll v10.42.0+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.7.0+0\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+1\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.11.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.59.0+0\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+2\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Manifest.toml`\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: ArgumentError: Package Colors not found in current path, maybe you meant `import/using .Colors`.\n- Otherwise, run `import Pkg; Pkg.add(\"Colors\")` to install the Colors package.\nin expression starting at /Users/clarasachmann/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Include.jl:16",
     "output_type": "error",
     "traceback": [
      "LoadError: ArgumentError: Package Colors not found in current path, maybe you meant `import/using .Colors`.\n- Otherwise, run `import Pkg; Pkg.add(\"Colors\")` to install the Colors package.\nin expression starting at /Users/clarasachmann/Documents/GitHub/CHEME-5820-Lectures-Spring-2025/lectures/week-3/L3a/Include.jl:16",
      "",
      "Stacktrace:",
      " [1] macro expansion",
      "   @ ./loading.jl:2296 [inlined]",
      " [2] macro expansion",
      "   @ ./lock.jl:273 [inlined]",
      " [3] __require(into::Module, mod::Symbol)",
      "   @ Base ./loading.jl:2271",
      " [4] #invoke_in_world#3",
      "   @ ./essentials.jl:1089 [inlined]",
      " [5] invoke_in_world",
      "   @ ./essentials.jl:1086 [inlined]",
      " [6] require(into::Module, mod::Symbol)",
      "   @ Base ./loading.jl:2260",
      " [7] include(fname::String)",
      "   @ Main ./sysimg.jl:38",
      " [8] top-level scope",
      "   @ In[1]:1"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ea87d-8177-4f3c-8bff-5b61ad6e2bcb",
   "metadata": {},
   "source": [
    "#### Boston housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdccc03-d8bf-491f-888e-4f9889b8f1c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `CSV` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `CSV` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:1"
     ]
    }
   ],
   "source": [
    "df_bostonhousingdata = CSV.read(joinpath(_PATH_TO_DATA, \"data-boston-housing.csv\"), DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3df2e2-72e9-4781-929a-d6e247777adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `df_bostonhousingdata` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df_bostonhousingdata` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[3]:1"
     ]
    }
   ],
   "source": [
    "D_housing = Matrix(df_bostonhousingdata); # get the data as a Matrix (alias for Array{Float64,2})\n",
    "number_of_training_examples_housing = 390; # how many training points for the housing dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78421b28-7047-44bb-bd73-a208ce5f9dca",
   "metadata": {},
   "source": [
    "Split the housing dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff3042e-a124-4b07-a612-c660fd9f78cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `D_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `D_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[4]:3"
     ]
    }
   ],
   "source": [
    "house_training, house_test = let\n",
    "\n",
    "    number_of_features = size(D_housing,2); # number of cols of housing data\n",
    "    number_of_examples = size(D_housing,1); # number of rows of housing data\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples_housing)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    house_training = D_housing[training_index_set |> collect,:];\n",
    "    house_test = D_housing[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    house_training,house_test\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb863d15-b46c-4281-9b4e-c952d0c03c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `house_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `house_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "house_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cd1b3-0b0b-4e36-9492-254e7ea7d8c5",
   "metadata": {},
   "source": [
    "#### Banknote Authentication Dataset\n",
    "The second dataset we will explore is the [banknote authentication dataset from the UCI archive](https://archive.ics.uci.edu/dataset/267/banknote+authentication). This dataset has 1372 instances of 4 continuous features and an integer $\\{-1,1\\}$ class indicator variable. \n",
    "* __Description__: Data were extracted from images taken from genuine and forged banknote-like specimens.  An industrial camera, usually used for print inspection, was used for digitization. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object, gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tools were used to extract features from images.\n",
    "* __Features__: The data has four continuous features from each image: `variance` of the wavelet transformed image, `skewness` of the wavelet transformed image, `kurtosis` of the wavelet transformed image, and the `entropy` of the wavelet transformed image. The class is $\\{-1,1\\}$ where a class value of `-1` indicates genuine, `1` forged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842d364e-12bf-41b4-8b7b-3b7eeb28610c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `CSV` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `CSV` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[6]:1"
     ]
    }
   ],
   "source": [
    "df_banknote = CSV.read(joinpath(_PATH_TO_DATA, \"data-banknote-authentication.csv\"), DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b304f85c-17bb-49de-b300-e4d5a8c66a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `df_banknote` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df_banknote` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[7]:1"
     ]
    }
   ],
   "source": [
    "D_banknote = Matrix(df_banknote); # get the data as a Matrix (alias for Array{Float64,2})\n",
    "number_of_training_examples_banknote = 1200; # how many training points for the banknote dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f30a56a-d55a-4bfa-97bf-35b12af80172",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `D_banknote` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `D_banknote` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[8]:3"
     ]
    }
   ],
   "source": [
    "banknote_training, banknote_test = let\n",
    "\n",
    "    number_of_features = size(D_banknote,2); # number of cols of housing data\n",
    "    number_of_examples = size(D_banknote,1); # number of rows of housing data\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples_housing)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    banknote_training = D_banknote[training_index_set |> collect,:];\n",
    "    banknote_test = D_banknote[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    banknote_training,banknote_test\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "182a8ab9-0f42-469a-8eea-a25af185d65a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `banknote_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `banknote_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "banknote_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16d67b-ec02-469e-9943-c95bec414fb0",
   "metadata": {},
   "source": [
    "## Linear regression models for continuous prediction tasks\n",
    "Suppose there exists a dataset $\\mathcal{D} = \\left\\{\\mathbf{x}_{i},y_{i}\\right\\}_{i=1}^{n}$ with $n$-training (labeled) examples, where $\\mathbf{x}_{i}\\in\\mathbb{R}^{p}$ is a $p$-vector of features (independent variables, typically real but potentially complex as well) and $y_{i}\\in\\mathbb{R}$ denotes a scalar response variable (dependent variable). Then, a $\\texttt{linear regression model}$ for the dataset $\\mathcal{D}$ takes the form:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "y_{i} = \\mathbf{x}_{i}^{T}\\cdot\\mathbf{\\beta} + \\epsilon_{i}\\qquad{i=1,2,\\dots,n}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{\\beta}\\in\\mathbb{R}^{p}$ is a $p\\times{1}$ vector of unknown model parameters, and $\\epsilon_{i}\\in\\mathbb{R}$ is the unobserved random error for response $i$. The linear regression model in matrix-vector form is given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{y} = \\mathbf{X}\\cdot\\mathbf{\\beta} + \\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{X}$ is an $n\\times{p}$ matrix with the features $\\mathbf{x}_{i}^{T}$ on the rows, \n",
    "the response vector $\\mathbf{y}$ is an $n\\times{1}$ vector with entries $y_{i}$, \n",
    "and the error vector $\\mathbf{\\epsilon}$ is an $n\\times{1}$ vector with entries $\\epsilon_{i}$. The challenge of linear regression is to estimate the unknown parameters $\\mathbf{\\beta}$ from the dataset $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ab630-1bc6-4c17-a40d-5ec591f41c68",
   "metadata": {},
   "source": [
    "### Case I: Overdetermined data matrix\n",
    "Let the data matrix $\\mathbf{X}$ be $\\texttt{overdetermined}$, i.e., $n > p$ (more rows than columns), and the error vector $\\mathbf{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\cdot\\mathbf{I})$.\n",
    "Then, the [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) estimate of the unknown parameters $\\mathbf{\\beta}$ will $\\textit{minimize}$ the sum of squared errors between model estimates and observed values:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\arg\\min_{\\mathbf{\\beta}} ||~\\mathbf{y} - \\mathbf{X}\\cdot\\mathbf{\\beta}~||^{2}_{2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $||\\star||^{2}_{2}$ is the square of the [`p = 2` vector norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm), and $\\hat{\\mathbf{\\beta}}$ denotes the estimated parameter vector.  The parameters $\\hat{\\mathbf{\\beta}}$ that minimize the $||\\star||^{2}_{2}$ loss for an overdetermined data matrix $\\mathbf{X}$ are given by:\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y} - \\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "The matrix $\\mathbf{X}^{T}\\mathbf{X}$ is the $\\texttt{normal matrix}$, while $\\mathbf{X}^{T}\\mathbf{y}$ is the $\\texttt{moment vector}$. The inverse $\\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}$ must exist to obtain the estimated model parameter vectors $\\hat{\\mathbf{\\beta}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fd2f9d-ddff-46a7-93ea-47ce2494b4aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `Normal` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Normal` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[10]:15"
     ]
    }
   ],
   "source": [
    "synthetic_experimental_data, μ, K = let\n",
    "\n",
    "    # Chymotrypsin actual parameters (only the oracle knows these), and experimental setup\n",
    "    number_of_substrate_samples = 100; # how many substrate samples will we measure?\n",
    "    number_of_enzyme_samples = 10; # how many enzyme concentrations will we measure?\n",
    "    number_of_replicates = 10; # how many estimates do we take per condition?\n",
    "    μ = 0.14*60; # units 1/min\n",
    "    K = 15.0; # units mM\n",
    "    E = range(0.01, stop=0.1,length=number_of_enzyme_samples) |> collect; # true: set of enzyme concentrations we'll explore (units: mM)\n",
    "    S = range(0.1, stop=3*K, length = number_of_substrate_samples) |> collect; # true: set of substate concentrations we'll explore (units: mM)\n",
    "    σ₁ = 0.001*K; # uncertainty in the substrate measurement\n",
    "    σ₂ = 0.01*μ; # uncertainty in the rate measurement\n",
    "    σ₃ = 0.001*mean(E); # uncertainty in the enzyme measurement\n",
    "\n",
    "    d₁ = Normal(0,σ₁); # measurement error substrate\n",
    "    d₂ = Normal(0,σ₂); # measurement error rate\n",
    "    d₃ = Normal(0,σ₃); # measurement error enzyme\n",
    "    \n",
    "    data = Array{Float64,3}(undef, number_of_substrate_samples*number_of_replicates, 3, number_of_enzyme_samples);\n",
    "\n",
    "    for i ∈ eachindex(E)\n",
    "        Ê = E[i]*(1+rand(d₃)); # what we *actually* used in the experiment (diff than what we thought by the error model)\n",
    "        rowindex = 1;\n",
    "        for j ∈ eachindex(S)\n",
    "            Ŝ = S[j]*(1+rand(d₁));\n",
    "            for k ∈ 1:number_of_replicates\n",
    "                r = (μ*Ê)*(Ŝ/(K+Ŝ))*(1+rand(d₂));                 \n",
    "                data[rowindex,1,i] = S[j]; # we record what we *think* should be there\n",
    "                data[rowindex,2,i] = E[i]; # we record what we *think* should be there\n",
    "                data[rowindex,3,i] = r; # measurement\n",
    "\n",
    "                # update -\n",
    "                rowindex += 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    data, μ, K; # return\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6239708f-0896-4aeb-b408-437d79e12096",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `synthetic_experimental_data` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `synthetic_experimental_data` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:2"
     ]
    }
   ],
   "source": [
    "let\n",
    "    scatter(synthetic_experimental_data[:,1,10],synthetic_experimental_data[:,3,10], c=:red, label=\"E = $(synthetic_experimental_data[1,2,10]) mM\")\n",
    "    scatter!(synthetic_experimental_data[:,1,5],synthetic_experimental_data[:,3,5], c=:navy, label=\"E = $(synthetic_experimental_data[1,2,5]) mM\")\n",
    "    xlabel!(\"Substrate S (mM)\", fontsize=18)\n",
    "    ylabel!(\"Rate r (mM/min)\", fontsize = 18);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63a47a-1588-42d5-a282-6dba73765302",
   "metadata": {},
   "source": [
    "Expected value of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8304ae8-d8b7-437d-88af-73efa79ed75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `synthetic_experimental_data` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `synthetic_experimental_data` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[12]:4"
     ]
    }
   ],
   "source": [
    "(μ̂,K̂,β,y,X,E) = let\n",
    "\n",
    "    enzyme_concentration_index = 10; # which case will we use?\n",
    "    data = synthetic_experimental_data[:,:,enzyme_concentration_index];\n",
    "    E = synthetic_experimental_data[1,2,enzyme_concentration_index];\n",
    "    (number_of_rows, number_of_cols) = size(data);\n",
    "\n",
    "    Y = zeros(number_of_rows); # output array\n",
    "    X = ones(number_of_rows,2); # data array\n",
    "    for i ∈ 1:number_of_rows\n",
    "        Y[i] = 1/data[i,3]; # 1/r value\n",
    "        X[i,2] = 1/data[i,1]; # 1/S value\n",
    "    end\n",
    "\n",
    "    # compute -\n",
    "    β = inv(transpose(X)*X)*transpose(X)*Y\n",
    "    μ̂ = (1/(β[1]*E));\n",
    "    K̂ = β[2]*μ̂*E;\n",
    "\n",
    "    # return \n",
    "    μ̂,K̂,β,Y,X,E\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74344c67-e295-4eb4-8c3c-aa7c6a74d047",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `DataFrame` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `DataFrame` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:2"
     ]
    }
   ],
   "source": [
    "let\n",
    "    df = DataFrame();\n",
    "    row_df = (\n",
    "        μ = μ,\n",
    "        μ̂ = μ̂,\n",
    "        rtol_μ = ((μ - μ̂)/μ)*100,\n",
    "        K = K,\n",
    "        K̂ = K̂,\n",
    "        rtol_K = ((K - K̂)/K)*100\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "    pretty_table(df, tf = tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508d95f-9fe8-4bc6-9dc8-6e5c2c68b16d",
   "metadata": {},
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cccec4-57d2-494e-986e-6547a55ce77d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[14]:4"
     ]
    }
   ],
   "source": [
    "p̂ = let\n",
    "\n",
    "    # compute the error model -\n",
    "    residual = y - X*β;\n",
    "    error_model = fit_mle(Normal, residual);\n",
    "    \n",
    "    \n",
    "    number_of_samples = 1000;\n",
    "    (number_of_rows, number_of_cols) = size(X);\n",
    "    β̂ = Array{Float64,2}(undef, number_of_samples, 2);\n",
    "    parameters = Array{Float64,2}(undef, number_of_samples, 2);\n",
    "    Z = inv(transpose(X)*X)*transpose(X);\n",
    "    is_ok_to_stop = false;\n",
    "    i = 1;\n",
    "    while (is_ok_to_stop == false)\n",
    "        \n",
    "        ϵ = rand(error_model, number_of_rows); # draw from the residual distribution\n",
    "        tmp = β - Z*ϵ;\n",
    "\n",
    "        if (tmp[1] > 0)\n",
    "            β̂[i,1] = tmp[1];\n",
    "            β̂[i,2] = tmp[2];\n",
    "            i += 1;\n",
    "        end\n",
    "        \n",
    "        if (i > number_of_samples)\n",
    "            is_ok_to_stop = true;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # ok, convert the beta samples back to bare parameters\n",
    "    for i ∈ 1:number_of_samples\n",
    "        μ = 1/(β̂[i,1]*E);\n",
    "        parameters[i,1] = μ;\n",
    "        parameters[i,2] = β̂[i,2]*μ*E;\n",
    "    end\n",
    "\n",
    "    parameters\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abac63bb-1ba6-457d-9cb0-58bca129558e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `p̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `p̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    μ̂ = mean(p̂[:,1]);\n",
    "    σ₁ = std(p̂[:,1]);\n",
    "    K̂ = mean(p̂[:,2]);\n",
    "    σ₂ = std(p̂[:,2]);\n",
    "    \n",
    "    df = DataFrame();\n",
    "    row_df = (\n",
    "        μ = μ,\n",
    "        μ̂ = μ̂,\n",
    "        σ₁ = σ₁,\n",
    "        rtol_μ = ((μ - μ̂)/μ)*100,\n",
    "        K = K,\n",
    "        K̂ = K̂,\n",
    "        σ₂ = σ₂,\n",
    "        rtol_K = ((K - K̂)/K)*100\n",
    "    );\n",
    "    push!(df, row_df);\n",
    "    pretty_table(df, tf = tf_simple)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63cadf06-87f0-4fea-b549-ec4774779292",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `house_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `house_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:3"
     ]
    }
   ],
   "source": [
    "β, X, y = let\n",
    "    \n",
    "    D = house_training; # what dataset are going to use?\n",
    "    number_of_examples = size(D,1); # how many examples do we have (rows)\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)]; # features: need to add a 1 to each row (for bias)\n",
    "    y = D[:,end]; # output: this is the target data\n",
    "\n",
    "    (number_of_examples, number_of_features) = size(X);\n",
    "    IM = Matrix(1.0*I, number_of_features, number_of_features);\n",
    "    A = inv(transpose(X)*X)*transpose(X);\n",
    "    β = A*y; # this is the expected value of the parameters w/o regularization\n",
    "\n",
    "    β,X,y\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d5cee-57ad-4b5f-b7ad-2dfc5e9552ec",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43773f53-8c7d-4536-adbe-fa407837f661",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[17]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    Y = Array{Float64,2}(undef, number_of_training_examples_housing, 2);\n",
    "    for i ∈ 1:number_of_training_examples_housing\n",
    "        Y[i,1] = dot(X[i,:],β);\n",
    "        Y[i,2] = y[i];\n",
    "    end\n",
    "\n",
    "    XYLINE = range(0,stop=50,length=100) |> collect;\n",
    "    scatter(Y[:,1], Y[:,2], c=:gray67, label=\"Training dataset\")\n",
    "    plot!(XYLINE,XYLINE,c=:red, lw=2, label=\"Equality\", ls=:dash)\n",
    "    xlabel!(\"Predicted target variable\", fontsize=18)\n",
    "    ylabel!(\"Observed target variable\", fontsize=18)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2302b-35bd-45e6-8284-dddbd6c33392",
   "metadata": {},
   "source": [
    "Goodness of fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba2ca306-ff6d-44a6-b1d9-b434f1bf365f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[18]:2"
     ]
    }
   ],
   "source": [
    "let\n",
    "    Y = Array{Float64,2}(undef, number_of_training_examples_housing, 2);\n",
    "    for i ∈ 1:number_of_training_examples_housing\n",
    "        Y[i,1] = dot(X[i,:],β);\n",
    "        Y[i,2] = y[i];\n",
    "    end\n",
    "    # ȳ = mean(Y[:,2]); # mean of the observed data\n",
    "    # SS_res = sum((Y[:,2] .- Y[:,1]).^2)\n",
    "    # SS_tol = sum((Y[:,2] .- ȳ).^2);\n",
    "    # Rsq = 1 - SS_res/SS_tol;\n",
    "    r = cor(Y[:,1], Y[:,2]) |> x-> x^2\n",
    "\n",
    "    df = DataFrame();\n",
    "    row_df = (\n",
    "        Rsq = r,\n",
    "        FUV = 1 - r\n",
    "    )\n",
    "    push!(df, row_df);\n",
    "    pretty_table(df, tf=tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7610f92-0b13-4cd3-bee5-a640088e8953",
   "metadata": {},
   "source": [
    "### Case II: Regularized linear regression models\n",
    "Regularized linear regression models incorporate penalty terms to constrain the size of the coefficient estimates, thereby reducing overfitting and enhancing the model's generalizability to new data. Consider an overdetermined data matrix $\\mathbf{X}\\in\\mathbb{R}^{n\\times{p}}$, i.e., the case where $n>p$ (more examples than unknown parameters).\n",
    "\n",
    "A regularized least squares estimate of the unknown parameters $\\mathbf{\\beta}$ for an _overdetermined_ system will _minimize_ a loss (objective) function of the form:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\arg\\min_{\\mathbf{\\beta}} ||~\\mathbf{y} - \\mathbf{X}\\cdot\\mathbf{\\beta}~||^{2}_{2} + \\lambda\\cdot||~\\mathbf{\\beta}~||^{2}_{2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $||\\star||^{2}_{2}$ is the square of the [`p = 2` vector norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm), $\\lambda\\geq{0}$ denotes a regularization parameter, and $\\hat{\\mathbf{\\beta}}$ denotes the estimated parameter vector. \n",
    "The parameters $\\hat{\\mathbf{\\beta}}$ that minimize the $||\\star||^{2}_{2}$ loss plus penalty for overdetermined data matrix $\\mathbf{X}$ are given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}}_{\\lambda} = \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y} - \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "$$\n",
    "The matrix $\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}$ is the $\\texttt{regularized normal matrix}$, while $\\mathbf{X}^{T}\\mathbf{y}$ is the $\\texttt{moment vector}$. The inverse $\\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}$ must exist to obtain the estimated parameter vector $\\hat{\\mathbf{\\beta}}_{\\lambda}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20c2e58a-c214-4eba-a947-45796a96ed47",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `number_of_training_examples_housing` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[19]:5"
     ]
    }
   ],
   "source": [
    "β̂, X, y, λ = let\n",
    "\n",
    "    # constants and data -\n",
    "    λ = 60.0; # regularization parameter λ ≥ 0 (60 is a good value)\n",
    "    number_of_samples = number_of_training_examples_housing; # we'll generate number_of_training_examples random parameters\n",
    "    D = house_training; # what dataset are going to use?\n",
    "    number_of_examples = size(D,1); # how many examples do we have (rows)\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)]; # features: need to add a 1 to each row (for bias)\n",
    "    y = D[:,end]; # output: this is the target data\n",
    "\n",
    "    (number_of_examples, number_of_features) = size(X);\n",
    "    IM = Matrix(1.0*I, number_of_features, number_of_features);\n",
    "    A = inv(transpose(X)*X + λ*IM)*transpose(X);\n",
    "\n",
    "    # compute the error model -\n",
    "    residual = y - X*A*y;\n",
    "    error_model = fit_mle(Normal, residual);\n",
    "\n",
    "    # sample the error model -\n",
    "    β̂ = Array{Float64,2}(undef, number_of_samples, number_of_features);\n",
    "    for s ∈ 1:number_of_samples\n",
    "        ϵ = rand(error_model, number_of_examples);\n",
    "        tmp = A*y - A*ϵ;\n",
    "        for j ∈ 1:number_of_features\n",
    "            β̂[s,j] = tmp[j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return the data\n",
    "    β̂, X, y, λ\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cbe75f1-f22b-4e7c-ba02-f83f2e435d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `β̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `β̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "β̂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "068e7a1f-220d-4705-b5b0-4a29ea2b34d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `fit_mle` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `fit_mle` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[21]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "    parameter_index = 1;\n",
    "    d = fit_mle(Normal,β̂[:,parameter_index])\n",
    "    density(β̂[:,parameter_index], label=\"Data\")\n",
    "    plot!(d, label=\"Normal distribution MLE\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6ab5f8d-178c-456a-a2a9-21a53c8a6c24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `β̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `β̂` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[22]:4"
     ]
    }
   ],
   "source": [
    "Y_training, Y_test = let\n",
    "\n",
    "    # training -\n",
    "    number_of_parameter_sets = size(β̂,1);\n",
    "    number_of_examples = size(X,1);\n",
    "    Y_training = Array{Float64,2}(undef, number_of_parameter_sets, 2);\n",
    "    for i ∈ 1:number_of_parameter_sets\n",
    "        Y_training[i,1] = dot(X[i,:],β̂[i,:]);\n",
    "        Y_training[i,2] = y[i] # training\n",
    "    end\n",
    "\n",
    "    # testing -\n",
    "    D = house_test; # what dataset are going to use?\n",
    "    number_of_examples = size(D,1); # how many examples do we have (rows) in the dataset D?\n",
    "    X_test = [D[:,1:end-1] ones(number_of_examples)]; # features: need to add a 1 to each row (for bias)\n",
    "    y_test = D[:,end]; # output: this is the target data\n",
    "    Y_test = Array{Float64,2}(undef, number_of_examples, 2);\n",
    "    for i ∈ 1:number_of_examples\n",
    "        Y_test[i,1] = dot(X_test[i,:],β̂[i,:]);\n",
    "        Y_test[i,2] = y_test[i] # training\n",
    "    end\n",
    "\n",
    "    Y_training, Y_test\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ef0b0-21d9-49c8-8a40-e9abac9d7adc",
   "metadata": {},
   "source": [
    "Visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5f07e8-6c7e-47ed-ad0a-f2eaa879b3e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `Y_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Y_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "    XYLINE = range(0,stop=50,length=100) |> collect;\n",
    "    scatter(Y_training[:,1], Y_training[:,2], c=:gray67, label=\"Training dataset\")\n",
    "    scatter!(Y_test[:,1], Y_test[:,2], c=:black, label=\"Test dataset\")\n",
    "    plot!(XYLINE,XYLINE,c=:red, lw=2, label=\"Equality\", ls=:dash)\n",
    "    xlabel!(\"Predicted target variable\", fontsize=18)\n",
    "    ylabel!(\"Observed target variable\", fontsize=18)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4bbd74-a93b-4909-a521-39726a3117ab",
   "metadata": {},
   "source": [
    "Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0605f5a9-7c06-446e-9e6e-5439be928609",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `Y_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Y_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[24]:2"
     ]
    }
   ],
   "source": [
    "let\n",
    "    r_training = cor(Y_training[:,1], Y_training[:,2]) |> x-> x^2\n",
    "    r_test = cor(Y_test[:,1], Y_test[:,2]) |> x-> x^2\n",
    "\n",
    "    df = DataFrame();\n",
    "    row_df = (\n",
    "        λ = λ,\n",
    "        Rsq_training = r_training,\n",
    "        FUV_training = 1 - r_training,\n",
    "        Rsq_test = r_test,\n",
    "        FUV_test = 1 - r_test,\n",
    "    )\n",
    "    push!(df, row_df);\n",
    "    pretty_table(df, tf=tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3999d-02f7-4ad2-9878-02626414cc6a",
   "metadata": {},
   "source": [
    "### Case III: Underdetermind data matrix\n",
    "Assume the data matrix $\\mathbf{X}$ is $\\texttt{underdetermined}$, i.e., $n < p$ (more columns than rows), and \n",
    "the error vector $\\mathbf{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\cdot\\mathbf{I})$.\n",
    "Then, an [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) estimate of the unknown parameters is the $\\textit{smallest}$ parameter vector $\\beta$ that satisfies the original equations:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{minimize}~& & ||\\,\\mathbf{\\beta}\\,|| \\\\\n",
    "\\text{subject to} & & \\mathbf{X}\\cdot\\mathbf{\\beta} = \\mathbf{y}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "The least-norm problem has an analytical estimate for the unknown parameter vector $\\hat{\\mathbf{\\beta}}$ given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} =\\mathbf{X}^{T}\\left(\\mathbf{X}\\mathbf{X}^{T}\\right)^{-1}\\cdot\\mathbf{y} - \\mathbf{X}^{T}\\left(\\mathbf{X}\\mathbf{X}^{T}\\right)^{-1}\\cdot\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where inverse $\\left(\\mathbf{X}\\mathbf{X}^{T}\\right)^{-1}$ must exist to obtain the estimated model parameter vectors $\\hat{\\mathbf{\\beta}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27010586-d186-4a2e-835e-0bdf3637810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a4a0b-d61b-4948-a94e-12ceac3a6a71",
   "metadata": {},
   "source": [
    "## Linear regression models for classification tasks\n",
    "Linear regression can be adapted for classification tasks by transforming the continuous output of the linear regression model directly to a class designation, e.g., $\\sigma:\\mathbb{R}\\rightarrow\\{-1,+1\\}$ or into a probability using an output function $\\sigma:\\mathbb{R}\\rightarrow\\mathbb{R}$ and applying a threshold to categorize predictions into discrete classes. Let's take a look at two examples of these strategies:\n",
    "\n",
    "* [The Perceptron (Rosenblatt, 1957)](https://en.wikipedia.org/wiki/Perceptron) is a simple yet powerful algorithm used in machine learning for binary classification tasks. It operates by _incrementally_ learning a linear decision boundary (linear regression model) that separates two classes based on input features by directly mapping the continuous output to a class such as $\\sigma:\\mathbb{R}\\rightarrow\\{-1,+1\\}$, where the output function is $\\sigma(\\star) = \\text{sign}(\\star)$.\n",
    "* [Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression#) is a statistical method used in machine learning for binary classification tasks using the [logistics function](https://en.wikipedia.org/wiki/Logistic_function) as the transformation function. Applying the logistic function transforms the output of a linear regression model into a probability, enabling effective decision-making in various applications. We'll consider this approach next time.\n",
    "\n",
    "### Perceptron\n",
    "[The Perceptron (Rosenblatt, 1957)](https://en.wikipedia.org/wiki/Perceptron) takes the (scalar) output of a linear regression model $y_{i}\\in\\mathbb{R}$ and then transforms it using the $\\sigma(\\star) = \\text{sign}(\\star)$ function to a discrete set of values representing categories, e.g., $\\sigma:\\mathbb{R}\\rightarrow\\{-1,1\\}$ in the binary classification case. \n",
    "* Suppose there exists a data set.\n",
    "$\\mathcal{D} = \\left\\{(\\mathbf{x}_{1},y_{1}),\\dotsc,(\\mathbf{x}_{m},y_{m})\\right\\}$ with $m$ _labeled_ examples, where each example $1,2,\\dots,m$ has been labeled by an expert, i.e., a human to be in a category $\\hat{y}_{i}\\in\\{-1,1\\}$, given the feature vector $\\mathbf{x}_{i}\\in\\mathbb{R}^{n}$. \n",
    "* The Perceptron _incrementally_ learns a linear decision boundary between _two_ classes of possible objects (binary classification) in $\\mathcal{D}$ by repeatedly processing the data. During each pass, a regression parameter vector $\\mathbf{\\beta}$ is updated until it makes no more than a specified number of mistakes. \n",
    "\n",
    "The Perceptron computes the label $\\hat{y}_{i}$ for feature vector $\\mathbf{x}_{i}$ using the $\\sigma(\\star) = \\text{sign}(\\star)$ function:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\hat{y}_{i} = \\text{sign}\\left(\\mathbf{x}_{i}^{T}\\cdot\\beta\\right)\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\beta=\\left(w_{1},\\dots,w_{n}, b\\right)$ is a column vector of (unknown) weight parameters $w_{j}\\in\\mathbb{R}$ corresponding to the importance of feature $j$ and a   bias parameter $b\\in\\mathbb{R}$, the features $\\mathbf{x}^{T}_{i}=\\left(x^{(i)}_{1},\\dots,x^{(i)}_{n}, 1\\right)$ is the $n+1$-dimensional feature (row) vector (features augmented with bias term), and $\\text{sign}(z)$ is the $\\texttt{sign}$ function:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\text{sign}(z) = \n",
    "    \\begin{cases}\n",
    "        1 & \\text{if}~z\\geq{0}\\\\\n",
    "        -1 & \\text{if}~z<0\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "__Hypothesis__: If data set $\\mathcal{D}$ is linearly separable, the Perceptron will _incrementally_ learn a separating hyperplane in a finite number of passes through the data set $\\mathcal{D}$. However, if the data set $\\mathcal{D}$ is not linearly separable, the Perceptron may not converge. Check out a [perceptron pseudo-code here!](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-3/L3a/figs/pcode-perceptron.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "895ae0c4-f06e-443b-932f-25d2528623cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `banknote_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `banknote_training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[26]:4"
     ]
    }
   ],
   "source": [
    "model = let\n",
    "\n",
    "    # data -\n",
    "    D = banknote_training; # what dataset are going to use?\n",
    "    number_of_examples = size(D,1); # how many examples do we have (rows)\n",
    "    number_of_features = size(D,2); # how many features do we have (cols)?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)]; # features: need to add a 1 to each row (for bias), after removing the label\n",
    "    y = D[:,end]; # output: this is the target data (label)\n",
    "\n",
    "    # model\n",
    "    model = build(MyPerceptronClassificationModel, (\n",
    "        parameters = ones(number_of_features),\n",
    "        mistakes = 0 # willing to like with m mistakes\n",
    "    ));\n",
    "\n",
    "    # train -\n",
    "    model = learn(X,y,model, maxiter = 1000, verbose = true);\n",
    "\n",
    "    # return -\n",
    "    model;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86842787-9cb1-4ab7-a8c1-ab479270d193",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `banknote_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `banknote_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[27]:3"
     ]
    }
   ],
   "source": [
    "ŷ,y = let\n",
    "\n",
    "    D = banknote_test; # what dataset are going to use?\n",
    "    number_of_examples = size(D,1); # how many examples do we have (rows)\n",
    "    number_of_features = size(D,2); # how many features do we have (cols)?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)]; # features: need to add a 1 to each row (for bias), after removing the label\n",
    "    y = D[:,end]; # output: this is the *actual* target data (label)\n",
    "\n",
    "    # compute the estimated labels -\n",
    "    ŷ = classify(X,model)\n",
    "\n",
    "    # return -\n",
    "    ŷ,y\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7015ac-cd96-4bf1-a04d-c61837d7b189",
   "metadata": {},
   "source": [
    "How many mistakes do the classifier make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beb55d97-d93d-40b7-8cff-b51506b1ac4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `ŷ` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `ŷ` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[28]:3"
     ]
    }
   ],
   "source": [
    "number_of_prediction_mistakes = let\n",
    "\n",
    "    number_of_test_examples = length(ŷ);\n",
    "    error_counter = 0;\n",
    "\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        if (ŷ[i] != y[i])\n",
    "            error_counter += 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    error_counter\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dd1c453-10a6-40fa-8009-e9d10e8261de",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `number_of_prediction_mistakes` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `number_of_prediction_mistakes` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[29]:1"
     ]
    }
   ],
   "source": [
    "println(\"Perceptron mistake percentage: $((number_of_prediction_mistakes/length(ŷ))*100)%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e5d06-26fc-45c0-8203-e5b284740be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
