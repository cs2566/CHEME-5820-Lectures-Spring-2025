{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d0c28b-498e-4e20-a8ea-8ea5a5aecbac",
   "metadata": {},
   "source": [
    "# Lecture 2a: Eigendecomposition of Data and Systems\n",
    "In this lecture, we will discuss the eigendecomposition of a square matrix and how it can be used to understand data and systems in unsupervised machine learning. There are several key ideas in this lecture:\n",
    "\n",
    "* __Eigendecomposition__ allows us to decompose a matrix into its constituent parts, the [eigenvectors and eigenvalues](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors). These values can help us understand the structure of the data or system represented by the matrix. We'll look at two approaches to estimate the [eigenvalues and eigenvectors](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors) of a matrix.\n",
    "* __Power iteration method__ estimates the _largest_ eigenvalue/eigenvector pair. Given a _diagonalizable_ matrix $\\mathbf{A}$ the power iteration algorithm will produce a number $\\lambda$, which is the greatest (in absolute value) eigenvalue of $\\mathbf{A}$ and a nonzero vector $\\mathbf{v}$ which is a corresponding eigenvector of $\\lambda$ such that $\\mathbf{A}\\mathbf{v} = \\lambda\\cdot\\mathbf{v}$.\n",
    "* __QR factorization__ is another approach to compute the eigendecomposition of the matrix $\\mathbf{A}$. However, unlike power iteration, this approach will give all eigenvalues and eigenvectors of the matrix $\\mathbf{A}$. The QR factorization algorithm relies on the [QR decomposition](https://en.wikipedia.org/wiki/QR_decomposition), which itself relies on the [Gram-Schmidt algorithm](https://en.wikipedia.org/wiki/Gram–Schmidt_process).\n",
    "\n",
    "Lecture notes can be found: [here!](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-2/L2a/docs/Notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9085c0c-4cbd-4e22-9b47-1127307d413f",
   "metadata": {},
   "source": [
    "## Setup and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0dc6e0-1af4-4406-af0f-67e920dac536",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde34514-8a96-4197-80e3-8aaa98834ab7",
   "metadata": {},
   "source": [
    "We'll use the coagulation dataset. Let's load this data from disk using [the `MySyntheticDataSet()` function](src/Files.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afab24e4-49f5-4235-bad3-014cfe722e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MySyntheticDataset() |> d-> d[\"ensemble\"]; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e02d2-4996-4279-acd9-ff1c2c99c622",
   "metadata": {},
   "source": [
    "The keys of the dataset dictionary are the `actual` patient indexes. These keys point to `synthetic` patient measurement vectors constructed by building a model of the original data distribution. To explore this data, specify an original patient index (one of the keys of the original dictionary) in the `original_patient_index::Int` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5d4612-a983-41c4-965a-d47fbe0ed083",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_patient_index = 7; # i ∈ {keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef3440-055c-4a50-b5bd-d4f9eab9f87a",
   "metadata": {},
   "source": [
    "Next, we'll build a data matrix with the `synthetic` measurement vectors for the specified original patient index. We'll store this in the `D::Array{<:Number, 1}` matrix. This data will be [z-score transformed](https://en.wikipedia.org/wiki/Standard_score), i.e., we center the data and normalize it by the standard deviation. Thus, all features will be on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fb8caa-66e6-401d-a70b-52ae03614baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33-element Vector{Float64}:\n",
       "    1.0\n",
       "    0.30836988\n",
       "    0.95415\n",
       " 1379.48378288\n",
       "   19.75514189\n",
       "   12.804792939999999\n",
       "    0.8867103181999999\n",
       "  115.60658202\n",
       "  156.28490704\n",
       "   15.33133564\n",
       "   11.96380865\n",
       " 3781.5834824\n",
       "   92.22819643799998\n",
       "    ⋮\n",
       "    1.737781717\n",
       "    1.631652416\n",
       " 1576.229293\n",
       "  227.991075025\n",
       "   36.51941662875\n",
       "    4.875\n",
       "   15.5\n",
       "   41.5\n",
       "   30.43333333\n",
       "   99.0\n",
       "   54.25833333\n",
       " 1545.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = dataset[original_patient_index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb22fb3-5846-48a1-b8fe-2330a8d921e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = let\n",
    "\n",
    "    M = dataset[original_patient_index];\n",
    "    number_of_rows = length(M); # number of synthetic patients\n",
    "    number_of_cols = length(M[1]) - 1; # number of measurements (features), first col is the visit number\n",
    "    D = Array{Float64,2}(undef, number_of_rows, number_of_cols);\n",
    "\n",
    "    for i ∈ 0:(number_of_rows - 1)\n",
    "        for j ∈ 1:(number_of_cols)\n",
    "            D[i+1,j] = M[i][j+1];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    D̂ = copy(D);\n",
    "    # for j ∈ 1:number_of_cols\n",
    "    #     sample_vector = D[:,j]; \n",
    "    #     μ = mean(sample_vector);\n",
    "    #     σ = std(sample_vector);\n",
    "\n",
    "    #     for i ∈ 1:number_of_rows\n",
    "    #         D̂[i,j] = (sample_vector[i] - μ)/σ;\n",
    "    #     end\n",
    "    # end\n",
    "    \n",
    "    D̂\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b149ccc-fc5b-4bc0-8382-8bce525934ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101×32 Matrix{Float64}:\n",
       " 0.30837    0.95415   1379.48  …  30.4333   99.0     54.2583  1545.5\n",
       " 1.05454    1.21144   1390.44     40.3337   99.6431  62.8345  1738.98\n",
       " 0.258829   1.19987   1402.45     50.2747   98.5461  73.2072  1716.69\n",
       " 0.367153   2.26673   1304.9      38.0187   99.541   57.4354  1955.18\n",
       " 0.990502   2.36371   1444.68     28.3245   99.4763  50.1078  1869.77\n",
       " 0.487677   0.765631  1300.14  …  27.3373   99.1424  35.3646  2051.73\n",
       " 0.369812   1.34229   1480.53     44.1981   98.9821  57.6517  2203.14\n",
       " 0.333311   1.25089   1401.56     53.1082   99.3418  82.3255  1759.01\n",
       " 0.380223   2.78909   1267.64     32.6413   99.9077  55.5721  1680.21\n",
       " 0.198641   0.154719  1487.26     46.1733   99.0888  71.642   1634.97\n",
       " 0.0579719  0.427665  1342.44  …  40.5358   99.6018  59.1068  1843.57\n",
       " 0.762005   3.74746   1509.31     27.9641   98.9494  49.195   2090.58\n",
       " 0.269213   1.24956   1300.79     32.8467   98.8762  50.2259  2330.19\n",
       " ⋮                             ⋱                      ⋮       \n",
       " 0.141033   1.18003   1324.03     33.1053   99.4486  59.1625  1683.32\n",
       " 0.180992   0.794416  1306.47  …  52.5861   99.426   74.3662  2060.37\n",
       " 0.37044    0.6945    1360.19     55.4063   99.0012  80.4913  1954.43\n",
       " 1.06901    0.975891  1267.07     30.4242   99.0939  41.7461  1732.98\n",
       " 0.201201   0.846638  1366.45     43.208   100.028   63.6383  1753.06\n",
       " 0.0212462  0.71889   1470.71     40.4809   98.8548  70.8927  1630.28\n",
       " 0.349349   0.696141  1378.34  …  32.2613   99.2761  58.9172  1547.59\n",
       " 0.408392   1.04074   1306.58     23.9261   99.737   43.8157  1805.0\n",
       " 0.491375   0.390921  1388.99     42.4397   99.1747  65.0989  1992.57\n",
       " 0.70842    0.810161  1270.06     46.3018   99.4722  80.2091  1710.47\n",
       " 0.207929   2.12205   1160.04     23.7747   98.761   42.9544  1330.25\n",
       " 0.431278   2.34703   1298.3   …  25.3683   99.3888  39.984   1707.58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d732d-e631-418c-b342-04b61cc08c1c",
   "metadata": {},
   "source": [
    "Finally, we set some constants that we'll use throughout the lecture. See the comment beside the constant value for its meaning, permissible values, units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d0f502-456a-4cca-acd2-be6859cd808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_examples = size(D,1); # number of synthetic patients\n",
    "number_of_features = size(D,2); # number of features (measurements)\n",
    "maxiter = 25000; # maximum number of iterations\n",
    "ϵ = 1e-8; # stopping criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a344371-a7f4-4377-aada-441a1aa149d1",
   "metadata": {},
   "source": [
    "## Eigendecomposition\n",
    "Suppose we have a real square matrix $\\mathbf{A}\\in\\mathbb{R}^{m\\times{m}}$ which could be a measurement dataset, e.g., the columns of $\\mathbf{A}$ represent feature \n",
    "vectors $\\mathbf{x}_{1},\\dots,\\mathbf{x}_{m}$ or an incidence array in a graph, etc. Eigenvalue-eigenvector problems involve finding a set of scalar values $\\left\\{\\lambda_{1},\\dots,\\lambda_{m}\\right\\}$ called \n",
    "[eigenvalues](https://mathworld.wolfram.com/Eigenvalue.html) and a set of linearly independent vectors \n",
    "$\\left\\{\\mathbf{v}_{1},\\dots,\\mathbf{v}_{m}\\right\\}$ called [eigenvectors](https://mathworld.wolfram.com/Eigenvector.html) such that:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{A}\\cdot\\mathbf{v}_{j} = \\lambda_{j}\\cdot\\mathbf{v}_{j}\\qquad{j=1,2,\\dots,m}\n",
    "\\end{equation}\n",
    "$$\n",
    "where $\\mathbf{v}\\in\\mathbb{R}^{m}$ and $\\lambda\\in\\mathbb{R}$. So, why is this interesting?\n",
    "* Eigenvectors represent fundamental directions of the matrix $\\mathbf{A}$. For the linear transformation defined by a matrix $\\mathbf{A}$, the eigenvectors are the only vectors that do not change direction during the transformation.\n",
    "* Eigenvalues are scale factors for their eigenvector. An eigenvalue is a scalar that indicates how much a corresponding eigenvector is stretched or compressed during a linear transformation represented by the matrix $\\mathbf{A}$.\n",
    "\n",
    "Another interpretation we'll explore later is that eigenvectors represent the most critical directions in the data or system, and the eigenvalues represent the importance of these directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f68694-55fd-4352-82e4-9956f7b48855",
   "metadata": {},
   "source": [
    "## Method 1: Power iteration\n",
    "The [power iteration method](https://en.wikipedia.org/wiki/Power_iteration) is an iterative algorithm to compute the largest eigenvalue and its corresponding eigenvector of a square (real) matrix; we'll consider only real-valued matrices here, but this approach can be used for matrices with complex entries. \n",
    "\n",
    "__Eigenvector__: Suppose we have a real-valued square _diagonalizable_ matrix $\\mathbf{A}\\in\\mathbb{R}^{m\\times{m}}$ whose eigenvalues have the property $|\\lambda_{1}|\\geq|\\lambda_{2}|\\dots\\geq|\\lambda_{m}|$. Then, the eigenvector $\\mathbf{v}_{1}$ which corresponds to the largest eigenvalue $\\lambda_{1}$ can be (iteratively) estimated as:\n",
    "$$\n",
    "\\mathbf{v}_{1}^{(k+1)} = \\frac{\\mathbf{A}\\mathbf{v}_{1}^{(k)}}{\\Vert \\mathbf{A}\\mathbf{v}_{1}^{(k)} \\Vert}\\quad{k=0,1,2\\dots}\n",
    "$$\n",
    "\n",
    "where $\\lVert \\star \\rVert$ denotes [some vector norm](https://mathworld.wolfram.com/VectorNorm.html), typically, the [L2 (Euclidean) norm](https://mathworld.wolfram.com/L2-Norm.html). The [power iteration method](https://en.wikipedia.org/wiki/Power_iteration) will converge to a value for the eigenvector as $k\\rightarrow\\infty$ when a few properties are true, namely, $|\\lambda_{1}|/|\\lambda_{2}| < 1$, and we pick an appropriate initial guess for $\\mathbf{v}_{1}$.\n",
    "\n",
    "__Eigenvalue__: Once we have an estimate for the eigenvector $\\hat{\\mathbf{v}}_{1}$, we can compute an estimate of the corresponding eigenvalue $\\hat{\\lambda}_{1}$ using [the Rayleigh quotient](https://en.wikipedia.org/wiki/Rayleigh_quotient). We know, from the definition of eigenvalue-eigenvector pairs, that:\n",
    "$$\n",
    "\\mathbf{A}\\hat{\\mathbf{v}}_{1} - \\hat{\\lambda}_{1}\\hat{\\mathbf{v}}_{1}\\simeq{0}\n",
    "$$\n",
    "To solve this for the eigenvalue $\\hat{\\lambda}_{1}$, we can multiply through by the transpose of the eigenvector and solve for the eigenvalue:\n",
    "$$\n",
    "\\hat{\\lambda}_{1} \\simeq \\frac{\\hat{\\mathbf{v}}_{1}^{T}\\mathbf{A}\\hat{\\mathbf{v}}_{1}}{\\hat{\\mathbf{v}}_{1}^{T}\\hat{\\mathbf{v}}_{1}}\n",
    "$$\n",
    "Note that we have used the $\\simeq$ symbol as this expression will give the true eigenvalue only when we have the true eigenvector. In our case, we have an approximation of the eigenvector, which could be a good or poor approximation depending on how many iterations we take.\n",
    "\n",
    "__Algorithm__\n",
    "* __Initialization__. We begin (iteration $k=0$) with an initial (random) guess of the eigenvector $\\mathbf{v}_{1}^{(0)}$, the maximum number of iterations we are willing to take `maxiter,` and a tolerance parameter $\\epsilon>0$.  \n",
    "* __Update__: Next, we repeatedly multiply the $\\mathbf{v}^{\\star}_{1}$ vector by the matrix $\\mathbf{A}$ and normalize the result by $\\Vert\\mathbf{A}\\mathbf{v}^{\\star}_{1}\\Vert$. This iterative approach capitalizes on the property that the dominant eigenvalue will exert the most influence on the vector $\\mathbf{v}$ over successive iterations, allowing it to converge towards the eigenvector associated with the largest eigenvalue.\n",
    "* __Stopping__: We stop the iteration procedure after `maxiter` number of iterations is reached or when the difference between successive iterations is _small_ in some sense, i.e., $\\lVert \\mathbf{v}_{1}^{(k)} - \\mathbf{v}_{1}^{(k-1)} \\rVert\\leq\\epsilon$. In practice, we'll use both stopping criteria to guard against an infinite loop.\n",
    "\n",
    "While simple and efficient, especially for large sparse matrices, the [power iteration method](https://en.wikipedia.org/wiki/Power_iteration) may exhibit slow convergence, mainly when the largest eigenvalue is close in magnitude to other eigenvalues.\n",
    "\n",
    "Additional references:\n",
    "* https://www.cs.cornell.edu/~bindel/class/cs6210-f16/lec/2016-10-17.pdf\n",
    "* https://blogs.sas.com/content/iml/2012/05/09/the-power-method.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e86e281-4205-4071-bf8e-16145097eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "(v,λ) = let\n",
    "\n",
    "    A = transpose(D)*D; # build a square matrix from the data\n",
    "    n = size(A,1); # how many rows (cols) do we have?\n",
    "    vₒ = randn(n); # initial random guess\n",
    "\n",
    "    # call the poweriteration function\n",
    "    (v,λ) = poweriteration(A, vₒ, maxiter = maxiter, ϵ = ϵ);\n",
    "\n",
    "    # return -\n",
    "    (v,λ)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4080a7-b124-4045-801d-121835f0042f",
   "metadata": {},
   "source": [
    "## Method 2: QR factorization and Gram-Schmidt\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7996efd3-fe2a-4aa4-a9a3-f7469c0d1338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}\n",
       "values:\n",
       "32-element Vector{Float64}:\n",
       "      0.7965972275689526\n",
       "      0.8701429641944097\n",
       "      2.039551836582301\n",
       "      2.7904185818636726\n",
       "      4.190406985710426\n",
       "     10.500815662637573\n",
       "     13.066580433098135\n",
       "     45.2197229642944\n",
       "     56.38952446979662\n",
       "     73.71270386779292\n",
       "    108.95065243994259\n",
       "    196.56312777062917\n",
       "    218.30174625892894\n",
       "      ⋮\n",
       "   8012.657170514377\n",
       "  10887.201683745288\n",
       "  17516.934946637335\n",
       "  31896.468087663383\n",
       "  51257.711158272316\n",
       "  70895.1030640178\n",
       " 515727.08641797875\n",
       "      2.0513055222368066e6\n",
       "      3.0972800898292297e6\n",
       "      4.241929776681231e6\n",
       "      1.4358778322967645e7\n",
       "      8.158508857877813e9\n",
       "vectors:\n",
       "32×32 Matrix{Float64}:\n",
       " -0.00178058    0.0385867     0.098397     …   0.000158009  -4.03042e-5\n",
       "  0.0447398    -0.0196024    -0.00142773       0.000314894  -0.000145721\n",
       "  0.000297513  -0.000988625  -0.00161957       0.177651     -0.148088\n",
       "  0.0390617    -0.00581845   -0.0149327        0.00344472   -0.00220036\n",
       " -0.0483561    -0.0425786     0.0846021        0.00116242   -0.00126853\n",
       " -0.654779     -0.693934     -0.0317681    …   0.000133714  -9.00124e-5\n",
       "  0.00669937   -0.00728502   -0.00514089       0.0178069    -0.0125568\n",
       " -0.000897078   0.00603387    0.000488631      0.0233065    -0.0170449\n",
       " -0.0351253     0.0308533     0.058622         0.00190338   -0.00141845\n",
       "  0.0289344    -0.0123942    -0.0145108        0.00210842   -0.00127319\n",
       "  0.000504187   0.000300705  -0.000850057  …   0.697348     -0.400578\n",
       "  0.00766803   -0.00492551   -0.00871126       0.014776     -0.0102943\n",
       " -0.50919       0.421741      0.715493         0.000349377  -0.000169274\n",
       "  ⋮                                        ⋱   ⋮            \n",
       "  0.0454987     0.0289058    -0.03919      …   0.000372033  -0.000166976\n",
       " -0.00303959   -0.00232143    0.000935356      0.000271497  -0.000672178\n",
       " -0.000380474  -0.000198422   0.000541965      0.493514     -0.148408\n",
       " -0.00259826   -0.00013085    0.00122982       0.0373216    -0.0199868\n",
       "  0.00423518   -0.00909419    0.00350468       0.00386971   -0.00428258\n",
       " -0.0961526    -0.231146      0.00993449   …   0.00102736   -0.000590437\n",
       " -0.0734577    -0.127896     -0.111146        -5.73387e-5   -0.0020161\n",
       " -0.0197712    -0.0161156    -0.0356447        0.00393233   -0.00507881\n",
       "  0.0496922    -0.0690055     0.00284186       0.00792667   -0.00412587\n",
       " -0.00932654    0.0251938     0.0167788        0.0168585    -0.011013\n",
       " -0.0368212     0.049168      0.00462657   …   0.0149116    -0.00643448\n",
       "  0.000751084   0.00190803    0.000835873      0.0122884    -0.201028"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = transpose(D)*D; # build a square matrix from the data\n",
    "eigen(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5b354-7a9d-4981-a356-a49896da1bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
